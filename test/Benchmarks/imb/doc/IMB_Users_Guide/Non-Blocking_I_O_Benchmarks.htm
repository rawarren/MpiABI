
<!doctype HTML public "-//W3C//DTD HTML 4.0 Frameset//EN">
<!-- saved from url=(0014)about:internet -->
<html>
<head>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
 <meta name="generator" content="Adobe RoboHelp 10">
<title>Nonblocking I/O Benchmarks</title>
<link rel="StyleSheet" href="styles_w_rh_ict.css" type="text/css">
<style title="hcp" type="text/css">
<!--
ul.hcp1 { list-style:disc; }
-->
</style>
</head>

<script src="NavScript.js" language="JavaScript1.2" type="text/javascript"></script>
<script language="JavaScript1.2" type="text/javascript">WriteNavLink(0);</script>
<body>
<script type="text/javascript" src="ehlpdhtm.js" language="JavaScript1.2"></script>

<div style="width: 100%; position: relative;" id="header">
	
 <p style="font-style: italic;">Intel® 
	 MPI Benchmarks 4.0</p>
</div>


<h1><a name="Non_blocking_I_O" id="Non_blocking_I_O"></a>IMB-IO Non-blocking 
 Benchmarks</h1>
<p>Intel® MPI Benchmarks implements blocking and nonblocking modes of 
 the IMB-IO benchmarks as different benchmark flavors. The <samp class="codeph">Read</samp> 
 and <samp class="codeph">Write</samp> components of the blocking benchmark 
 name are replaced&#160;for nonblocking flavors by <samp class="codeph">IRead</samp> 
 and <samp class="codeph">IWrite</samp>, respectively.</p>
<p>The definitions of blocking and nonblocking flavors are identical, 
 except for their behavior in regard to:</p>
<ul class="hcp1">
	<li><p>Aggregation. The nonblocking versions only run in the non-aggregate 
	 mode.</p></li>
	<li><p>Synchronism. Only the meaning of an elementary transfer differs 
	 from the equivalent blocking benchmark.</p></li>
</ul>
<p>Basically, an elementary transfer looks as follows:</p>
<pre>
time = MPI_Wtime()
for ( i=0; i&lt;n_sample; i++ )
{
Initiate transfer
Exploit CPU
Wait for the end of transfer
}
time = (MPI_Wtime()-time)/n_sample</pre>
<p>The <samp class="codeph">Exploit CPU</samp> section in the above example 
 is arbitrary. Intel® MPI Benchmarks exploits CPU as described below.</p>
<h2>Exploiting CPU</h2>
<p>Intel® MPI Benchmarks uses the following method to exploit the CPU. 
 A kernel loop is executed repeatedly. The kernel is a fully vectorizable 
 multiplication of a 100x100 matrix with a vector. The function is scalable 
 in the following way:</p>
<p><samp class="codeph">IMB_cpu_exploit(float desired_time, int initialize);</samp></p>
<p>The input value of <samp class="codeph">desired_time</samp> determines 
 the time for the function to execute the kernel loop, with a slight variance. 
 At the very beginning, the function is called with <samp class="codeph">initialize=1</samp> 
 and an input value for <samp class="codeph">desired_time</samp>. This 
 determines an Mflop/s rate and a timing <samp class="codeph">t_CPU</samp>, 
 as close as possible to <samp class="codeph">desired_time</samp>, obtained 
 by running without any obstruction. During the actual benchmarking, <samp 
	 class="codeph">IMB_cpu_exploit</samp> is called with <samp class="codeph">initialize=0</samp>, 
 concurrently with the particular I/O action, and always performs the same 
 type and number of operations as in the initialization step.</p>
<h2>Displaying Results</h2>
<p>Three timings are crucial to interpret the behavior of nonblocking 
 I/O, overlapped with CPU exploitation:</p>
<ul class="hcp1">
	<li><p><samp class="codeph">t_pure</samp> is the time for the corresponding 
	 pure blocking I/O action, non-overlapping with CPU activity</p></li>
	<li><p><samp class="codeph">t_CPU</samp>&#160;&#160;is the time the 
	 <samp class="codeph">IMB_cpu_exploit</samp> periods (running concurrently 
	 with nonblocking I/O) would use when running dedicated</p></li>
	<li><p><samp class="codeph">t_ovrl</samp> is the time for the analogous 
	 nonblocking I/O action, concurrent with CPU activity (exploiting 
	 <samp class="codeph">t_CPU</samp> when running dedicated)</p></li>
</ul>
<p>A perfect overlap means: <samp class="codeph">t_ovrl&#160;=&#160;max(t_pure,t_CPU)</samp></p>
<p>No overlap means: <samp class="codeph">t_ovrl&#160;=&#160;t_pure+t_CPU</samp>.</p>
<p>The actual amount of overlap is: <samp class="codeph">&#160;</samp></p>
<p><samp class="codeph">overlap=(t_pure+t_CPU-t_ovrl)/min(t_pure,t_CPU)</samp>(*)</p>
<p>The Intel® MPI Benchmarks result tables report the timings <samp class="codeph">t_ovrl, 
 t_pure, t_CPU</samp> and the estimated overlap obtained by the (*) formula 
 above. At the beginning of a run, the Mflop/s rate is corresponding to 
 the <samp class="codeph">t_CPU</samp> displayed.</p>
<div>
<div class="docfeedback">
	<p style="font-family: Verdana, sans-serif; font-size: 10pt; font-weight: bold; 
		 color: #0860A8;"><span 
	 style="font-weight: bold; color: #0860A8;"><a href="http://www.intel.com/software/products/softwaredocs_feedback" 
													 target="_blank" style="text-decoration: none; "><b>Submit 
	 feedback on this help topic</b></a></span></p>
</div>
</div>
</body>
</html>
